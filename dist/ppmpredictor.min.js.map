{"version":3,"file":"ppmpredictor.min.js","sources":["../assert","../src/vocabulary.js","../src/ppm_language_model.js","../src/utils/fuzzy-matcher.js","../src/utils/word-tokenizer.js","../src/index.browser.js?commonjs-entry","../src/index.browser.js","../src/predictor.js"],"sourcesContent":["\n        export default function assert(condition, message) {\n          if (!condition) {\n            throw new Error(message || 'Assertion failed');\n          }\n        }\n      ","// Copyright 2025 The Google Research Authors.\r\n//\r\n// Licensed under the Apache License, Version 2.0 (the \"License\");\r\n// you may not use this file except in compliance with the License.\r\n// You may obtain a copy of the License at\r\n//\r\n//     http://www.apache.org/licenses/LICENSE-2.0\r\n//\r\n// Unless required by applicable law or agreed to in writing, software\r\n// distributed under the License is distributed on an \"AS IS\" BASIS,\r\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n// See the License for the specific language governing permissions and\r\n// limitations under the License.\r\n\r\n/**\r\n * @fileoverview Simple vocabulary abstraction.\r\n *\r\n * This is used to store symbols and map them to contiguous integers.\r\n */\r\n\r\n// Special symbol denoting the root node.\r\nconst rootSymbol = 0;\r\n\r\n// Symbol name of the root symbol, also used for out-of-vocabulary symbols.\r\nconst rootSymbolName = \"<R>\";\r\n\r\n// The special out-of-vocabulary (OOV) symbol.\r\nconst oovSymbol = \"<OOV>\";\r\n\r\n/**\r\n * Vocabulary of symbols, which is a set of symbols that map one-to-one to\r\n * unique integers.\r\n * @final\r\n */\r\nclass Vocabulary {\r\n  constructor() {\r\n    this.symbols_ = Array();\r\n    this.symbols_.push(rootSymbolName);\r\n    this.oovSymbol_ = -1;\r\n  }\r\n\r\n  /**\r\n   * Adds symbol to the vocabulary returning its unique ID.\r\n   * @param {string} symbol Symbol to be added.\r\n   * @return {number} Symbol ID.\r\n   * @final\r\n   */\r\n  addSymbol(symbol) {\r\n    let pos = this.symbols_.indexOf(symbol);\r\n    if (pos >= 0) {\r\n      return pos;\r\n    }\r\n    // The current symbol container length is used as a unique ID. Because\r\n    // the symbol IDs are used to index the array directly, the symbol ID is\r\n    // assigned before updating the array.\r\n    const symbol_id = this.symbols_.length;\r\n    this.symbols_.push(symbol);\r\n    return symbol_id;\r\n  }\r\n\r\n  /**\r\n   * Returns the vocabulary symbol ID if it exists, otherwise maps the supplied\r\n   * symbol to out-of-vocabulary (OOV) symbol. Note, this method is *only* used\r\n   * for testing.\r\n   * @param {string} symbol Symbol to be looked up.\r\n   * @return {number} Symbol ID.\r\n   * @final\r\n   */\r\n  getSymbolOrOOV(symbol) {\r\n    let pos = this.symbols_.indexOf(symbol);\r\n    if (pos >= 0) {\r\n      return pos;\r\n    }\r\n    this.oovSymbol_ = this.addSymbol(oovSymbol);\r\n    return this.oovSymbol_;\r\n  }\r\n\r\n  /**\r\n   * Returns cardinality of the vocabulary.\r\n   * @return {number} Size.\r\n   * @final\r\n   */\r\n  size() {\r\n    return this.symbols_.length;\r\n  }\r\n}\r\n\r\n/**\r\n * Exported APIs.\r\n */\r\nexports.rootSymbol = rootSymbol;\r\nexports.Vocabulary = Vocabulary;","// Copyright 2025 The Google Research Authors.\r\n//\r\n// Licensed under the Apache License, Version 2.0 (the \"License\");\r\n// you may not use this file except in compliance with the License.\r\n// You may obtain a copy of the License at\r\n//\r\n//     http://www.apache.org/licenses/LICENSE-2.0\r\n//\r\n// Unless required by applicable law or agreed to in writing, software\r\n// distributed under the License is distributed on an \"AS IS\" BASIS,\r\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n// See the License for the specific language governing permissions and\r\n// limitations under the License.\r\n\r\n/**\r\n * @fileoverview Prediction by Partial Matching (PPM) language model.\r\n *\r\n * The original PPM algorithm is described in [1]. This particular\r\n * implementation has been inspired by the PPM model used by Dasher, an\r\n * Augmentative and alternative communication (AAC) input method developed by\r\n * the Inference Group at University of Cambridge. The overview of the system\r\n * is provided in [2]. The details of this algorithm, which is different from\r\n * the standard PPM, are outlined in general terms in [3]. Please also see [4]\r\n * for an excellent overview of various PPM variants.\r\n *\r\n * References:\r\n * -----------\r\n *   [1] Cleary, John G. and Witten, Ian H. (1984): “Data Compression Using\r\n *       Adaptive Coding and Partial String Matching”, IEEE Transactions on\r\n *       Communications, vol. 32, no. 4, pp. 396–402.\r\n *   [2] Ward, David J. and Blackwell, Alan F. and MacKay, David J. C. (2000):\r\n *       “Dasher - A Data Entry Interface Using Continuous Gestures and\r\n *       Language Models”, UIST'00 Proceedings of the 13th annual ACM symposium\r\n *       on User interface software and technology, pp. 129–137, November, San\r\n *       Diego, USA.\r\n *   [3] Cowans, Phil (2005): “Language Modelling In Dasher -- A Tutorial”,\r\n *       June, Inference Lab, Cambridge University (presentation).\r\n *   [4] Jin Hu Huang and David Powers (2004): \"Adaptive Compression-based\r\n *       Approach for Chinese Pinyin Input.\" Proceedings of the Third SIGHAN\r\n *       Workshop on Chinese Language Processing, pp. 24--27, Barcelona, Spain,\r\n *       ACL.\r\n * Please also consult the references in README.md file in this directory.\r\n */\r\n\r\nconst assert = require(\"assert\");\r\n\r\nconst vocab = require(\"./vocabulary\");\r\n\r\n/**\r\n * Kneser-Ney \"-like\" smoothing parameters.\r\n *\r\n * These hardcoded values are copied from Dasher. Please see the documentation\r\n * for PPMLanguageModel.getProbs() below for more information.\r\n */\r\nconst knAlpha = 0.49;\r\nconst knBeta = 0.77;\r\n\r\n/* Epsilon for sanity checks. */\r\nconst epsilon = 1E-10;\r\n\r\n/**\r\n * Node in a search tree, which is implemented as a suffix trie that represents\r\n * every suffix of a sequence used during its construction. Please see\r\n *   [1] Moffat, Alistair (1990): \"Implementing the PPM data compression\r\n *       scheme\", IEEE Transactions on Communications, vol. 38, no. 11, pp.\r\n *       1917--1921.\r\n *   [2] Esko Ukknonen (1995): \"On-line construction of suffix trees\",\r\n *       Algorithmica, volume 14, pp. 249--260, Springer, 1995.\r\n *   [3] Kennington, C. (2011): \"Application of Suffix Trees as an\r\n *       Implementation Technique for Varied-Length N-gram Language Models\",\r\n *       MSc. Thesis, Saarland University.\r\n *\r\n * @final\r\n */\r\nclass Node {\r\n  constructor() {\r\n    // Leftmost child node for the current node.\r\n    this.child_ = null;\r\n    // Next node.\r\n    this.next_ = null;\r\n    // Node in the backoff structure, also known as \"vine\" structure (see [1]\r\n    // above) and \"suffix link\" (see [2] above). The backoff for the given node\r\n    // points at the node representing the shorter context. For example, if the\r\n    // current node in the trie represents string \"AA\" (corresponding to the\r\n    // branch \"[R] -> [A] -> [*A*]\" in the trie, where [R] stands for root),\r\n    // then its backoff points at the node \"A\" (represented by \"[R] ->\r\n    // [*A*]\"). In this case both nodes are in the same branch but they don't\r\n    // need to be. For example, for the node \"B\" in the trie path for the string\r\n    // \"AB\" (\"[R] -> [A] -> [*B*]\") the backoff points at the child node of a\r\n    // different path \"[R] -> [*B*]\".\r\n    this.backoff_ = null;\r\n    // Frequency count for this node. Number of times the suffix symbol stored\r\n    // in this node was observed.\r\n    this.count_ = 1;\r\n    // Symbol that this node stores.\r\n    this.symbol_ = vocab.rootSymbol;\r\n  }\r\n\r\n  /**\r\n   * Finds child of the current node with a specified symbol.\r\n   * @param {number} symbol Integer symbol.\r\n   * @return {?Node} Node with the symbol.\r\n   * @final\r\n   */\r\n  findChildWithSymbol(symbol) {\r\n    let current = this.child_;\r\n    while (current != null) {\r\n      if (current.symbol_ == symbol) {\r\n        return current;\r\n      }\r\n      current = current.next_;\r\n    }\r\n    return current;\r\n  }\r\n\r\n  /**\r\n   * Total number of observations for all the children of this node. This\r\n   * counts all the events observed in this context.\r\n   *\r\n   * Note: This API is used at inference time. A possible alternative that will\r\n   * speed up the inference is to store the number of children in each node as\r\n   * originally proposed by Moffat for PPMB in\r\n   *   Moffat, Alistair (1990): \"Implementing the PPM data compression scheme\",\r\n   *   IEEE Transactions on Communications, vol. 38, no. 11, pp. 1917--1921.\r\n   * This however will increase the memory use of the algorithm which is already\r\n   * quite substantial.\r\n   *\r\n   * @param {!array} exclusionMask Boolean exclusion mask for all the symbols.\r\n   *                 Can be 'null', in which case no exclusion happens.\r\n   * @return {number} Total number of observations under this node.\r\n   * @final\r\n   */\r\n  totalChildrenCounts(exclusionMask) {\r\n    let childNode = this.child_;\r\n    let count = 0;\r\n    while (childNode != null) {\r\n      if (!exclusionMask || !exclusionMask[childNode.symbol_]) {\r\n        count += childNode.count_;\r\n      }\r\n      childNode = childNode.next_;\r\n    }\r\n    return count;\r\n  }\r\n}\r\n\r\n/**\r\n * Handle encapsulating the search context.\r\n * @final\r\n */\r\nclass Context {\r\n  /**\r\n   * Constructor.\r\n   * @param {?Node} head Head node of the context.\r\n   * @param {number} order Length of the context.\r\n   */\r\n  constructor(head, order) {\r\n    // Current node.\r\n    this.head_ = head;\r\n    // The order corresponding to length of the context.\r\n    this.order_ = order;\r\n  }\r\n}\r\n\r\n/**\r\n * Prediction by Partial Matching (PPM) Language Model.\r\n * @final\r\n */\r\nclass PPMLanguageModel {\r\n  /**\r\n   * @param {?Vocabulary} vocab Symbol vocabulary object.\r\n   * @param {number} maxOrder Maximum length of the context.\r\n   */\r\n  constructor(vocab, maxOrder) {\r\n    this.vocab_ = vocab;\r\n    assert(this.vocab_.size() > 1,\r\n           \"Expecting at least two symbols in the vocabulary\");\r\n\r\n    this.maxOrder_ = maxOrder;\r\n    this.root_ = new Node();\r\n    this.rootContext_ = new Context();\r\n    this.rootContext_.head_ = this.root_;\r\n    this.rootContext_.order_ = 0;\r\n    this.numNodes_ = 1;\r\n\r\n    // Exclusion mechanism: Off by default, but can be enabled during the\r\n    // run-time once the constructed suffix tree contains reliable counts.\r\n    this.useExclusion_ = false;\r\n  }\r\n\r\n  /**\r\n   * Adds symbol to the supplied node.\r\n   * @param {?Node} node Tree node which to grow.\r\n   * @param {number} symbol Symbol.\r\n   * @return {?Node} Node with the symbol.\r\n   * @final @private\r\n   */\r\n  addSymbolToNode_(node, symbol) {\r\n    let symbolNode = node.findChildWithSymbol(symbol);\r\n    if (symbolNode != null) {\r\n      // Update the counts for the given node.  Only updates the counts for\r\n      // the highest order already existing node for the symbol ('single\r\n      // counting' or 'update exclusion').\r\n      symbolNode.count_++;\r\n    } else {\r\n      // Symbol does not exist under the given node. Create a new child node\r\n      // and update the backoff structure for lower contexts.\r\n      symbolNode = new Node();\r\n      symbolNode.symbol_ = symbol;\r\n      symbolNode.next_ = node.child_;\r\n      node.child_ = symbolNode;\r\n      this.numNodes_++;\r\n      if (node == this.root_) {\r\n        // Shortest possible context.\r\n        symbolNode.backoff_ = this.root_;\r\n      } else {\r\n        assert(node.backoff_ != null, \"Expected valid backoff node\");\r\n        symbolNode.backoff_ = this.addSymbolToNode_(node.backoff_, symbol);\r\n      }\r\n    }\r\n    return symbolNode;\r\n  }\r\n\r\n  /**\r\n   * Creates new context which is initially empty.\r\n   * @return {?Context} Context object.\r\n   * @final\r\n   */\r\n  createContext() {\r\n    return new Context(this.rootContext_.head_, this.rootContext_.order_);\r\n  }\r\n\r\n  /**\r\n   * Clones existing context.\r\n   * @param {?Context} context Existing context object.\r\n   * @return {?Context} Cloned context object.\r\n   * @final\r\n   */\r\n  cloneContext(context) {\r\n    return new Context(context.head_, context.order_);\r\n  }\r\n\r\n  /**\r\n   * Adds symbol to the supplied context. Does not update the model.\r\n   * @param {?Context} context Context object.\r\n   * @param {number} symbol Integer symbol.\r\n   * @final\r\n   */\r\n  addSymbolToContext(context, symbol) {\r\n    if (symbol <= vocab.rootSymbol) {  // Only add valid symbols.\r\n      return;\r\n    }\r\n    assert(symbol < this.vocab_.size(), \"Invalid symbol: \" + symbol);\r\n    while (context.head_ != null) {\r\n      if (context.order_ < this.maxOrder_) {\r\n        // Extend the current context.\r\n        const childNode = context.head_.findChildWithSymbol(symbol);\r\n        if (childNode != null) {\r\n          context.head_ = childNode;\r\n          context.order_++;\r\n          return;\r\n        }\r\n      }\r\n      // Try to extend the shorter context.\r\n      context.order_--;\r\n      context.head_ = context.head_.backoff_;\r\n    }\r\n    if (context.head_ == null) {\r\n      context.head_ = this.root_;\r\n      context.order_ = 0;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Adds symbol to the supplied context and updates the model.\r\n   * @param {?Context} context Context object.\r\n   * @param {number} symbol Integer symbol.\r\n   * @final\r\n   */\r\n  addSymbolAndUpdate(context, symbol) {\r\n    if (symbol <= vocab.rootSymbol) {  // Only add valid symbols.\r\n      return;\r\n    }\r\n    assert(symbol < this.vocab_.size(), \"Invalid symbol: \" + symbol);\r\n    const symbolNode = this.addSymbolToNode_(context.head_, symbol);\r\n    assert(symbolNode == context.head_.findChildWithSymbol(symbol));\r\n    context.head_ = symbolNode;\r\n    context.order_++;\r\n    while (context.order_ > this.maxOrder_) {\r\n      context.head_ = context.head_.backoff_;\r\n      context.order_--;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Returns probabilities for all the symbols in the vocabulary given the\r\n   * context.\r\n   *\r\n   * Notation:\r\n   * ---------\r\n   *         $x_h$ : Context representing history, $x_{h-1}$ shorter context.\r\n   *   $n(w, x_h)$ : Count of symbol $w$ in context $x_h$.\r\n   *      $T(x_h)$ : Total count in context $x_h$.\r\n   *      $q(x_h)$ : Number of symbols with non-zero counts seen in context\r\n   *                 $x_h$, i.e. |{w' : c(x_h, w') > 0}|. Alternatively, this\r\n   *                 represents the number of distinct extensions of history\r\n   *                 $x_h$ in the training data.\r\n   *\r\n   * Standard Kneser-Ney method (aka Absolute Discounting):\r\n   * ------------------------------------------------------\r\n   * Subtracting \\beta (in [0, 1)) from all counts.\r\n   *   P_{kn}(w | x_h) = \\frac{\\max(n(w, x_h) - \\beta, 0)}{T(x_h)} +\r\n   *                     \\beta * \\frac{q(x_h)}{T(x_h)} * P_{kn}(w | x_{h-1}),\r\n   * where the second term in summation represents escaping to lower-order\r\n   * context.\r\n   *\r\n   * See: Ney, Reinhard and Kneser, Hermann (1995): “Improved backing-off for\r\n   * M-gram language modeling”, Proc. of Acoustics, Speech, and Signal\r\n   * Processing (ICASSP), May, pp. 181–184.\r\n   *\r\n   * Modified Kneser-Ney method (Dasher version [3]):\r\n   * ------------------------------------------------\r\n   * Introducing \\alpha parameter (in [0, 1)) and estimating as\r\n   *   P_{kn}(w | x_h) = \\frac{\\max(n(w, x_h) - \\beta, 0)}{T(x_h) + \\alpha} +\r\n   *                     \\frac{\\alpha + \\beta * q(x_h)}{T(x_h) + \\alpha} *\r\n   *                     P_{kn}(w | x_{h-1}) .\r\n   *\r\n   * Additional details on the above version are provided in Sections 3 and 4\r\n   * of:\r\n   *   Steinruecken, Christian and Ghahramani, Zoubin and MacKay, David (2016):\r\n   *   \"Improving PPM with dynamic parameter updates\", In Proc. Data\r\n   *   Compression Conference (DCC-2015), pp. 193--202, April, Snowbird, UT,\r\n   *   USA. IEEE.\r\n   *\r\n   * @param {?Context} context Context symbols.\r\n   * @return {?array} Array of floating point probabilities corresponding to all\r\n   *                  the symbols in the vocabulary plus the 0th element\r\n   *                  representing the root of the tree that should be ignored.\r\n   * @final\r\n   */\r\n  getProbs(context) {\r\n    // Initialize the initial estimates. Note, we don't use uniform\r\n    // distribution here.\r\n    const numSymbols = this.vocab_.size();\r\n    let probs = new Array(numSymbols);\r\n    for (let i = 0; i < numSymbols; ++i) {\r\n      probs[i] = 0.0;\r\n    }\r\n\r\n    // Initialize the exclusion mask.\r\n    let exclusionMask = null;\r\n    if (this.useExclusion_) {\r\n      exclusionMask = new Array(numSymbols);\r\n      for (let i = 0; i < numSymbols; ++i) {\r\n        exclusionMask[i] = false;\r\n      }\r\n    }\r\n\r\n    // Estimate the probabilities for all the symbols in the supplied context.\r\n    // This runs over all the symbols in the context and over all the suffixes\r\n    // (orders) of the context. If the exclusion mechanism is enabled, the\r\n    // estimate for a higher-order ngram is fully trusted and is excluded from\r\n    // further interpolation with lower-order estimates.\r\n    //\r\n    // Exclusion mechanism is disabled by default. Enable it with care: it has\r\n    // been shown to work well on large corpora, but may in theory degrade the\r\n    // performance on smaller sets (as we observed with default Dasher English\r\n    // training data).\r\n    let totalMass = 1.0;\r\n    let node = context.head_;\r\n    let gamma = totalMass;\r\n    while (node != null) {\r\n      const count = node.totalChildrenCounts(exclusionMask);\r\n      if (count > 0) {\r\n        let childNode = node.child_;\r\n        while (childNode != null) {\r\n          const symbol = childNode.symbol_;\r\n          if (!exclusionMask || !exclusionMask[symbol]) {\r\n            const p = gamma * (childNode.count_ - knBeta) / (count + knAlpha);\r\n            probs[symbol] += p;\r\n            totalMass -= p;\r\n            if (exclusionMask) {\r\n              exclusionMask[symbol] = true;\r\n            }\r\n          }\r\n          childNode = childNode.next_;\r\n        }\r\n      }\r\n\r\n      // Backoff to lower-order context. The $\\gamma$ factor represents the\r\n      // total probability mass after processing the current $n$-th order before\r\n      // backing off to $n-1$-th order. It roughly corresponds to the usual\r\n      // interpolation parameter, as used in the literature, e.g. in\r\n      //   Stanley F. Chen and Joshua Goodman (1999): \"An empirical study of\r\n      //   smoothing techniques for language modeling\", Computer Speech and\r\n      //   Language, vol. 13, pp. 359-–394.\r\n      //\r\n      // Note on computing $gamma$:\r\n      // --------------------------\r\n      // According to the PPM papers, and in particular the Section 4 of\r\n      //   Steinruecken, Christian and Ghahramani, Zoubin and MacKay,\r\n      //   David (2016): \"Improving PPM with dynamic parameter updates\", In\r\n      //   Proc. Data Compression Conference (DCC-2015), pp. 193--202, April,\r\n      //   Snowbird, UT, USA. IEEE,\r\n      // that describes blending (i.e. interpolation), the second multiplying\r\n      // factor in the interpolation $\\lambda$ for a given suffix node $x_h$ in\r\n      // the tree is given by\r\n      //   \\lambda(x_h) = \\frac{q(x_h) * \\beta + \\alpha}{T(x_h) + \\alpha} .\r\n      // It can be shown that\r\n      //   \\gamma(x_h) = 1.0 - \\sum_{w'}\r\n      //      \\frac{\\max(n(w', x_h) - \\beta, 0)}{T(x_h) + \\alpha} =\r\n      //      \\lambda(x_h)\r\n      // and, in the update below, the following is equivalent:\r\n      //   \\gamma = \\gamma * \\gamma(x_h) = totalMass .\r\n      //\r\n      // Since gamma *= (numChildren * knBeta + knAlpha) / (count + knAlpha) is\r\n      // expensive, we assign the equivalent totalMass value to gamma.\r\n      node = node.backoff_;\r\n      gamma = totalMass;\r\n    }\r\n    assert(totalMass >= 0.0,\r\n           \"Invalid remaining probability mass: \" + totalMass);\r\n\r\n    // Count the total number of symbols that should have their estimates\r\n    // blended with the uniform distribution representing the zero context.\r\n    // When exclusion mechanism is enabled (by enabling this.useExclusion_)\r\n    // this number will represent the number of symbols not seen during the\r\n    // training, otherwise, this number will be equal to total number of\r\n    // symbols because we always interpolate with the estimates for an empty\r\n    // context.\r\n    let numUnseenSymbols = 0;\r\n    for (let i = 1; i < numSymbols; ++i) {\r\n      if (!exclusionMask || !exclusionMask[i]) {\r\n        numUnseenSymbols++;\r\n      }\r\n    }\r\n\r\n    // Adjust the probability mass for all the symbols.\r\n    const remainingMass = totalMass;\r\n    for (let i = 1; i < numSymbols; ++i) {\r\n      // Following is estimated according to a uniform distribution\r\n      // corresponding to the context length of zero.\r\n      if (!exclusionMask || !exclusionMask[i]) {\r\n        const p = remainingMass / numUnseenSymbols;\r\n        probs[i] += p;\r\n        totalMass -= p;\r\n      }\r\n    }\r\n    let leftSymbols = numSymbols - 1;\r\n    let newProbMass = 0.0;\r\n    for (let i = 1; i < numSymbols; ++i) {\r\n      const p = totalMass / leftSymbols;\r\n      probs[i] += p;\r\n      totalMass -= p;\r\n      newProbMass += probs[i];\r\n      --leftSymbols;\r\n    }\r\n    assert(totalMass == 0.0, \"Expected remaining probability mass to be zero!\");\r\n    assert(Math.abs(1.0 - newProbMass) < epsilon);\r\n    return probs;\r\n  }\r\n\r\n  /**\r\n   * Prints the trie to console.\r\n   * @param {?Node} node Current trie node.\r\n   * @param {string} indent Indentation prefix.\r\n   * @final @private\r\n   */\r\n  printToConsole_(node, indent) {\r\n    console.log(indent + \"  \" + this.vocab_.symbols_[node.symbol_] +\r\n                \"(\" + node.symbol_ + \") [\" + node.count_ + \"]\");\r\n    indent += \"  \";\r\n    let child = node.child_;\r\n    while (child != null) {\r\n      this.printToConsole_(child, indent);\r\n      child = child.next_;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Prints the trie to console.\r\n   * @final\r\n   */\r\n  printToConsole() {\r\n    this.printToConsole_(this.root_, \"\");\r\n  }\r\n}\r\n\r\n/**\r\n * Exported APIs.\r\n */\r\nexports.PPMLanguageModel = PPMLanguageModel;","// Copyright 2025 Will Wade\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Fuzzy matching utilities for error-tolerant prediction.\n * \n * Provides functions for calculating string similarity and filtering\n * predictions based on edit distance and other similarity metrics.\n */\n\n/**\n * Calculate Levenshtein distance between two strings.\n * @param {string} str1 First string.\n * @param {string} str2 Second string.\n * @return {number} Edit distance.\n */\nfunction levenshteinDistance(str1, str2) {\n  const len1 = str1.length;\n  const len2 = str2.length;\n  \n  // Create a 2D array for dynamic programming\n  const dp = Array(len1 + 1).fill(null).map(() => Array(len2 + 1).fill(0));\n  \n  // Initialize base cases\n  for (let i = 0; i <= len1; i++) {\n    dp[i][0] = i;\n  }\n  for (let j = 0; j <= len2; j++) {\n    dp[0][j] = j;\n  }\n  \n  // Fill the dp table\n  for (let i = 1; i <= len1; i++) {\n    for (let j = 1; j <= len2; j++) {\n      if (str1[i - 1] === str2[j - 1]) {\n        dp[i][j] = dp[i - 1][j - 1];\n      } else {\n        dp[i][j] = Math.min(\n          dp[i - 1][j] + 1,      // deletion\n          dp[i][j - 1] + 1,      // insertion\n          dp[i - 1][j - 1] + 1   // substitution\n        );\n      }\n    }\n  }\n  \n  return dp[len1][len2];\n}\n\n/**\n * Calculate similarity score between two strings (0-1, higher is more similar).\n * @param {string} str1 First string.\n * @param {string} str2 Second string.\n * @return {number} Similarity score between 0 and 1.\n */\nfunction similarityScore(str1, str2) {\n  const maxLen = Math.max(str1.length, str2.length);\n  if (maxLen === 0) return 1.0;\n  \n  const distance = levenshteinDistance(str1, str2);\n  return 1.0 - (distance / maxLen);\n}\n\n/**\n * Check if a string starts with a prefix (case-insensitive option).\n * @param {string} str The string to check.\n * @param {string} prefix The prefix to look for.\n * @param {boolean} caseSensitive Whether to do case-sensitive matching.\n * @return {boolean} True if str starts with prefix.\n */\nfunction startsWith(str, prefix, caseSensitive = true) {\n  if (!caseSensitive) {\n    str = str.toLowerCase();\n    prefix = prefix.toLowerCase();\n  }\n  return str.startsWith(prefix);\n}\n\n/**\n * Filter and rank strings by similarity to a target string.\n * @param {string} target Target string to match against.\n * @param {Array<string>} candidates Array of candidate strings.\n * @param {number} maxDistance Maximum edit distance to include.\n * @param {number} minSimilarity Minimum similarity score (0-1) to include.\n * @return {Array<{text: string, distance: number, similarity: number}>} \n *         Sorted array of matches with scores.\n */\nfunction fuzzyMatch(target, candidates, maxDistance = 2, minSimilarity = 0.5) {\n  const matches = [];\n  \n  for (const candidate of candidates) {\n    const distance = levenshteinDistance(target, candidate);\n    const similarity = similarityScore(target, candidate);\n    \n    if (distance <= maxDistance && similarity >= minSimilarity) {\n      matches.push({\n        text: candidate,\n        distance: distance,\n        similarity: similarity\n      });\n    }\n  }\n  \n  // Sort by similarity (descending) then by distance (ascending)\n  matches.sort((a, b) => {\n    if (Math.abs(a.similarity - b.similarity) > 0.001) {\n      return b.similarity - a.similarity;\n    }\n    return a.distance - b.distance;\n  });\n  \n  return matches;\n}\n\n/**\n * Get keyboard adjacency map for QWERTY layout.\n * Used for keyboard-proximity-based error tolerance.\n * @return {Object} Map of characters to their adjacent keys.\n */\nfunction getQwertyAdjacency() {\n  return {\n    'q': ['w', 'a', 's'],\n    'w': ['q', 'e', 'a', 's', 'd'],\n    'e': ['w', 'r', 's', 'd', 'f'],\n    'r': ['e', 't', 'd', 'f', 'g'],\n    't': ['r', 'y', 'f', 'g', 'h'],\n    'y': ['t', 'u', 'g', 'h', 'j'],\n    'u': ['y', 'i', 'h', 'j', 'k'],\n    'i': ['u', 'o', 'j', 'k', 'l'],\n    'o': ['i', 'p', 'k', 'l'],\n    'p': ['o', 'l'],\n    'a': ['q', 'w', 's', 'z', 'x'],\n    's': ['q', 'w', 'e', 'a', 'd', 'z', 'x', 'c'],\n    'd': ['w', 'e', 'r', 's', 'f', 'x', 'c', 'v'],\n    'f': ['e', 'r', 't', 'd', 'g', 'c', 'v', 'b'],\n    'g': ['r', 't', 'y', 'f', 'h', 'v', 'b', 'n'],\n    'h': ['t', 'y', 'u', 'g', 'j', 'b', 'n', 'm'],\n    'j': ['y', 'u', 'i', 'h', 'k', 'n', 'm'],\n    'k': ['u', 'i', 'o', 'j', 'l', 'm'],\n    'l': ['i', 'o', 'p', 'k'],\n    'z': ['a', 's', 'x'],\n    'x': ['a', 's', 'd', 'z', 'c'],\n    'c': ['s', 'd', 'f', 'x', 'v'],\n    'v': ['d', 'f', 'g', 'c', 'b'],\n    'b': ['f', 'g', 'h', 'v', 'n'],\n    'n': ['g', 'h', 'j', 'b', 'm'],\n    'm': ['h', 'j', 'k', 'n']\n  };\n}\n\n/**\n * Check if two characters are adjacent on a QWERTY keyboard.\n * @param {string} char1 First character.\n * @param {string} char2 Second character.\n * @return {boolean} True if characters are adjacent.\n */\nfunction areKeysAdjacent(char1, char2) {\n  const adjacency = getQwertyAdjacency();\n  const c1 = char1.toLowerCase();\n  const c2 = char2.toLowerCase();\n  \n  return adjacency[c1] && adjacency[c1].includes(c2);\n}\n\n/**\n * Calculate keyboard-aware edit distance.\n * Substitutions between adjacent keys cost less than non-adjacent keys.\n * @param {string} str1 First string.\n * @param {string} str2 Second string.\n * @return {number} Keyboard-aware edit distance.\n */\nfunction keyboardAwareDistance(str1, str2) {\n  const len1 = str1.length;\n  const len2 = str2.length;\n  \n  const dp = Array(len1 + 1).fill(null).map(() => Array(len2 + 1).fill(0));\n  \n  for (let i = 0; i <= len1; i++) {\n    dp[i][0] = i;\n  }\n  for (let j = 0; j <= len2; j++) {\n    dp[0][j] = j;\n  }\n  \n  for (let i = 1; i <= len1; i++) {\n    for (let j = 1; j <= len2; j++) {\n      if (str1[i - 1] === str2[j - 1]) {\n        dp[i][j] = dp[i - 1][j - 1];\n      } else {\n        // Check if keys are adjacent for substitution cost\n        const substCost = areKeysAdjacent(str1[i - 1], str2[j - 1]) ? 0.5 : 1.0;\n        \n        dp[i][j] = Math.min(\n          dp[i - 1][j] + 1,              // deletion\n          dp[i][j - 1] + 1,              // insertion\n          dp[i - 1][j - 1] + substCost   // substitution\n        );\n      }\n    }\n  }\n  \n  return dp[len1][len2];\n}\n\n/**\n * Exported APIs.\n */\nexports.levenshteinDistance = levenshteinDistance;\nexports.similarityScore = similarityScore;\nexports.startsWith = startsWith;\nexports.fuzzyMatch = fuzzyMatch;\nexports.getQwertyAdjacency = getQwertyAdjacency;\nexports.areKeysAdjacent = areKeysAdjacent;\nexports.keyboardAwareDistance = keyboardAwareDistance;\n\n","// Copyright 2025 Will Wade\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Word tokenization utilities.\n * \n * Provides functions for splitting text into words and handling\n * word boundaries for prediction.\n */\n\n/**\n * Tokenize text into words.\n * @param {string} text Text to tokenize.\n * @return {Array<string>} Array of words.\n */\nfunction tokenize(text) {\n  if (!text || typeof text !== 'string') {\n    return [];\n  }\n  \n  // Split on whitespace and punctuation, but keep the tokens\n  return text.trim().split(/\\s+/).filter(word => word.length > 0);\n}\n\n/**\n * Get the last partial word from text (for word completion).\n * @param {string} text Input text.\n * @return {string} The last partial word.\n */\nfunction getLastPartialWord(text) {\n  if (!text || typeof text !== 'string') {\n    return '';\n  }\n  \n  const trimmed = text.trimEnd();\n  const words = trimmed.split(/\\s+/);\n  \n  // If text ends with whitespace, there's no partial word\n  if (text !== trimmed) {\n    return '';\n  }\n  \n  return words[words.length - 1] || '';\n}\n\n/**\n * Get the context (all words except the last partial word).\n * @param {string} text Input text.\n * @return {string} Context text.\n */\nfunction getContext(text) {\n  if (!text || typeof text !== 'string') {\n    return '';\n  }\n  \n  const trimmed = text.trimEnd();\n  const words = trimmed.split(/\\s+/);\n  \n  // If text ends with whitespace, all words are context\n  if (text !== trimmed) {\n    return trimmed;\n  }\n  \n  // Otherwise, exclude the last word\n  if (words.length <= 1) {\n    return '';\n  }\n  \n  return words.slice(0, -1).join(' ');\n}\n\n/**\n * Check if text ends with a word boundary (whitespace).\n * @param {string} text Input text.\n * @return {boolean} True if text ends with whitespace.\n */\nfunction endsWithWordBoundary(text) {\n  if (!text || typeof text !== 'string') {\n    return true;\n  }\n  \n  return text !== text.trimEnd();\n}\n\n/**\n * Normalize text for prediction (lowercase, trim).\n * @param {string} text Input text.\n * @param {boolean} lowercase Whether to convert to lowercase.\n * @return {string} Normalized text.\n */\nfunction normalize(text, lowercase = true) {\n  if (!text || typeof text !== 'string') {\n    return '';\n  }\n  \n  let normalized = text.trim();\n  if (lowercase) {\n    normalized = normalized.toLowerCase();\n  }\n  \n  return normalized;\n}\n\n/**\n * Split text into characters, handling special cases.\n * @param {string} text Input text.\n * @return {Array<string>} Array of characters.\n */\nfunction toCharArray(text) {\n  if (!text || typeof text !== 'string') {\n    return [];\n  }\n  \n  return Array.from(text);\n}\n\n/**\n * Join an array of characters into a string.\n * @param {Array<string>} chars Array of characters.\n * @return {string} Joined string.\n */\nfunction fromCharArray(chars) {\n  if (!Array.isArray(chars)) {\n    return '';\n  }\n  \n  return chars.join('');\n}\n\n/**\n * Get n-grams from text.\n * @param {string} text Input text.\n * @param {number} n Size of n-grams.\n * @return {Array<string>} Array of n-grams.\n */\nfunction getNgrams(text, n) {\n  if (!text || typeof text !== 'string' || n < 1) {\n    return [];\n  }\n  \n  const chars = toCharArray(text);\n  const ngrams = [];\n  \n  for (let i = 0; i <= chars.length - n; i++) {\n    ngrams.push(chars.slice(i, i + n).join(''));\n  }\n  \n  return ngrams;\n}\n\n/**\n * Remove punctuation from text.\n * @param {string} text Input text.\n * @return {string} Text without punctuation.\n */\nfunction removePunctuation(text) {\n  if (!text || typeof text !== 'string') {\n    return '';\n  }\n  \n  return text.replace(/[^\\w\\s]/g, '');\n}\n\n/**\n * Check if a character is alphanumeric.\n * @param {string} char Character to check.\n * @return {boolean} True if alphanumeric.\n */\nfunction isAlphanumeric(char) {\n  if (!char || typeof char !== 'string' || char.length !== 1) {\n    return false;\n  }\n  \n  return /^[a-zA-Z0-9]$/.test(char);\n}\n\n/**\n * Check if a character is whitespace.\n * @param {string} char Character to check.\n * @return {boolean} True if whitespace.\n */\nfunction isWhitespace(char) {\n  if (!char || typeof char !== 'string' || char.length !== 1) {\n    return false;\n  }\n  \n  return /^\\s$/.test(char);\n}\n\n/**\n * Exported APIs.\n */\nexports.tokenize = tokenize;\nexports.getLastPartialWord = getLastPartialWord;\nexports.getContext = getContext;\nexports.endsWithWordBoundary = endsWithWordBoundary;\nexports.normalize = normalize;\nexports.toCharArray = toCharArray;\nexports.fromCharArray = fromCharArray;\nexports.getNgrams = getNgrams;\nexports.removePunctuation = removePunctuation;\nexports.isAlphanumeric = isAlphanumeric;\nexports.isWhitespace = isWhitespace;\n\n","import { getDefaultExportFromCjs } from \"\u0000commonjsHelpers.js\";\nimport { __require as requireIndex_browser } from \"C:\\\\Users\\\\admin.will\\\\Documents\\\\GitHub\\\\noisy-channel-correction\\\\js\\\\src\\\\index.browser.js\";\nvar index_browserExports = requireIndex_browser();\nexport { index_browserExports as __moduleExports };\nexport default /*@__PURE__*/getDefaultExportFromCjs(index_browserExports);","// Copyright 2025 Will Wade\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Browser-compatible entry point for noisy-channel-predictor.\n * \n * This version excludes Node.js-specific dependencies (like fs) and provides\n * a browser-friendly API.\n */\n\nconst predictorModule = require('./predictor');\nconst ppmModule = require('./ppm_language_model');\nconst vocabModule = require('./vocabulary');\nconst fuzzyMatcher = require('./utils/fuzzy-matcher');\nconst wordTokenizer = require('./utils/word-tokenizer');\n\n// Extract the actual classes from the modules\nconst Predictor = predictorModule.Predictor || predictorModule;\nconst PPMLanguageModel = ppmModule.PPMLanguageModel || ppmModule;\nconst Vocabulary = vocabModule.Vocabulary || vocabModule;\n\n/**\n * Create a new predictor instance.\n * \n * @param {Object} config - Configuration options\n * @returns {Predictor} Predictor instance\n */\nfunction createPredictor(config = {}) {\n  return new Predictor(config);\n}\n\n/**\n * Create a predictor with strict mode (exact matching only).\n * \n * @param {Object} config - Configuration options\n * @returns {Predictor} Predictor instance\n */\nfunction createStrictPredictor(config = {}) {\n  return new Predictor({\n    ...config,\n    errorTolerant: false\n  });\n}\n\n/**\n * Create a predictor with error-tolerant mode enabled.\n * \n * @param {Object} config - Configuration options\n * @returns {Predictor} Predictor instance\n */\nfunction createErrorTolerantPredictor(config = {}) {\n  return new Predictor({\n    ...config,\n    errorTolerant: true\n  });\n}\n\n// Export for different module systems\nconst PPMPredictor = {\n  // Factory functions\n  createPredictor,\n  createStrictPredictor,\n  createErrorTolerantPredictor,\n\n  // Classes\n  Predictor,\n  PPMLanguageModel,\n  Vocabulary,\n\n  // Utilities\n  fuzzyMatcher,\n  wordTokenizer,\n\n  // Convenience exports\n  levenshteinDistance: fuzzyMatcher.levenshteinDistance,\n  similarityScore: fuzzyMatcher.similarityScore,\n  fuzzyMatch: fuzzyMatcher.fuzzyMatch\n};\n\n// UMD export\nif (typeof module !== 'undefined' && module.exports) {\n  // CommonJS\n  module.exports = PPMPredictor;\n  module.exports.createPredictor = createPredictor;\n  module.exports.createStrictPredictor = createStrictPredictor;\n  module.exports.createErrorTolerantPredictor = createErrorTolerantPredictor;\n  module.exports.Predictor = Predictor;\n  module.exports.PPMLanguageModel = PPMLanguageModel;\n  module.exports.Vocabulary = Vocabulary;\n  module.exports.fuzzyMatcher = fuzzyMatcher;\n  module.exports.wordTokenizer = wordTokenizer;\n  module.exports.levenshteinDistance = fuzzyMatcher.levenshteinDistance;\n  module.exports.similarityScore = fuzzyMatcher.similarityScore;\n  module.exports.fuzzyMatch = fuzzyMatcher.fuzzyMatch;\n}\n\nif (typeof window !== 'undefined') {\n  // Browser global\n  window.PPMPredictor = PPMPredictor;\n}\n\n// Default export\nmodule.exports = PPMPredictor;\n\n","// Copyright 2025 Will Wade\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview High-level prediction API wrapping PPM language model.\n * \n * Provides word and letter prediction with configurable error tolerance.\n */\n\nconst ppm = require('./ppm_language_model');\nconst vocab = require('./vocabulary');\nconst fuzzy = require('./utils/fuzzy-matcher');\nconst tokenizer = require('./utils/word-tokenizer');\n\n/**\n * Configuration options for the predictor.\n * @typedef {Object} PredictorConfig\n * @property {number} maxOrder - Maximum context length for PPM (default: 5)\n * @property {boolean} errorTolerant - Enable error-tolerant mode (default: false)\n * @property {number} maxEditDistance - Maximum edit distance for fuzzy matching (default: 2)\n * @property {number} minSimilarity - Minimum similarity score 0-1 (default: 0.5)\n * @property {boolean} keyboardAware - Use keyboard-aware distance (default: false)\n * @property {boolean} caseSensitive - Case-sensitive matching (default: false)\n * @property {number} maxPredictions - Maximum number of predictions to return (default: 10)\n * @property {boolean} adaptive - Update model as text is entered (default: false)\n * @property {Array<string>} lexicon - Optional word list for word prediction\n */\n\n/**\n * Prediction result.\n * @typedef {Object} Prediction\n * @property {string} text - Predicted text\n * @property {number} probability - Probability score (0-1)\n * @property {number} [distance] - Edit distance (only in error-tolerant mode)\n * @property {number} [similarity] - Similarity score (only in error-tolerant mode)\n */\n\n/**\n * Predictor class providing word and letter prediction.\n */\nclass Predictor {\n  /**\n   * Constructor.\n   * @param {PredictorConfig} config Configuration options.\n   */\n  constructor(config = {}) {\n    // Set default configuration\n    this.config = {\n      maxOrder: config.maxOrder || 5,\n      errorTolerant: config.errorTolerant !== undefined ? config.errorTolerant : false,\n      maxEditDistance: config.maxEditDistance || 2,\n      minSimilarity: config.minSimilarity || 0.5,\n      keyboardAware: config.keyboardAware !== undefined ? config.keyboardAware : false,\n      caseSensitive: config.caseSensitive !== undefined ? config.caseSensitive : false,\n      maxPredictions: config.maxPredictions || 10,\n      adaptive: config.adaptive !== undefined ? config.adaptive : false,\n      lexicon: config.lexicon || []\n    };\n\n    // Create vocabulary\n    this.vocab = new vocab.Vocabulary();\n    \n    // Add all printable ASCII characters to vocabulary\n    for (let i = 32; i <= 126; i++) {\n      this.vocab.addSymbol(String.fromCharCode(i));\n    }\n    \n    // Add common special characters\n    this.vocab.addSymbol('\\n');\n    this.vocab.addSymbol('\\t');\n    \n    // Create PPM language model\n    this.model = new ppm.PPMLanguageModel(this.vocab, this.config.maxOrder);\n    \n    // Create context\n    this.context = this.model.createContext();\n    \n    // Build lexicon index if provided\n    this.lexiconIndex = new Set(this.config.lexicon.map(word => \n      this.config.caseSensitive ? word : word.toLowerCase()\n    ));\n  }\n\n  /**\n   * Train the model on text.\n   * @param {string} text Training text.\n   */\n  train(text) {\n    if (!text || typeof text !== 'string') {\n      return;\n    }\n\n    const chars = tokenizer.toCharArray(text);\n    const context = this.model.createContext();\n    \n    for (const char of chars) {\n      const symbolId = this.vocab.addSymbol(char);\n      this.model.addSymbolAndUpdate(context, symbolId);\n    }\n  }\n\n  /**\n   * Reset the prediction context.\n   */\n  resetContext() {\n    this.context = this.model.createContext();\n  }\n\n  /**\n   * Add text to the current context.\n   * @param {string} text Text to add to context.\n   * @param {boolean} update Whether to update the model (adaptive mode).\n   */\n  addToContext(text, update = null) {\n    if (!text || typeof text !== 'string') {\n      return;\n    }\n\n    const shouldUpdate = update !== null ? update : this.config.adaptive;\n    const chars = tokenizer.toCharArray(text);\n    \n    for (const char of chars) {\n      let symbolId = this.vocab.symbols_.indexOf(char);\n      if (symbolId < 0) {\n        symbolId = this.vocab.addSymbol(char);\n      }\n      \n      if (shouldUpdate) {\n        this.model.addSymbolAndUpdate(this.context, symbolId);\n      } else {\n        this.model.addSymbolToContext(this.context, symbolId);\n      }\n    }\n  }\n\n  /**\n   * Get character/letter predictions.\n   * @param {string} context Optional context string (uses current context if not provided).\n   * @return {Array<Prediction>} Array of character predictions.\n   */\n  predictNextCharacter(context = null) {\n    let workingContext = this.context;\n    \n    if (context !== null) {\n      workingContext = this.model.createContext();\n      const chars = tokenizer.toCharArray(context);\n      for (const char of chars) {\n        let symbolId = this.vocab.symbols_.indexOf(char);\n        if (symbolId < 0) {\n          symbolId = this.vocab.addSymbol(char);\n        }\n        this.model.addSymbolToContext(workingContext, symbolId);\n      }\n    }\n\n    // Get probabilities from PPM model\n    const probs = this.model.getProbs(workingContext);\n    \n    // Convert to predictions array\n    const predictions = [];\n    for (let i = 1; i < probs.length; i++) {\n      if (probs[i] > 0) {\n        predictions.push({\n          text: this.vocab.symbols_[i],\n          probability: probs[i]\n        });\n      }\n    }\n    \n    // Sort by probability (descending)\n    predictions.sort((a, b) => b.probability - a.probability);\n    \n    // Return top N predictions\n    return predictions.slice(0, this.config.maxPredictions);\n  }\n\n  /**\n   * Get word completion predictions.\n   * @param {string} partialWord Partial word to complete.\n   * @param {string} precedingContext Optional preceding context.\n   * @return {Array<Prediction>} Array of word predictions.\n   */\n  predictWordCompletion(partialWord, precedingContext = '') {\n    if (!partialWord || typeof partialWord !== 'string') {\n      return [];\n    }\n\n    const normalized = this.config.caseSensitive ? partialWord : partialWord.toLowerCase();\n    \n    // If we have a lexicon, use it for word completion\n    if (this.lexiconIndex.size > 0) {\n      return this._predictFromLexicon(normalized, precedingContext);\n    }\n    \n    // Otherwise, use character-level prediction to build word completions\n    return this._predictCharacterBased(partialWord, precedingContext);\n  }\n\n  /**\n   * Predict word completions from lexicon.\n   * @param {string} partialWord Partial word (normalized).\n   * @param {string} precedingContext Preceding context.\n   * @return {Array<Prediction>} Array of word predictions.\n   * @private\n   */\n  _predictFromLexicon(partialWord, precedingContext) {\n    const candidates = [];\n    \n    // Find all words in lexicon that start with the partial word\n    for (const word of this.lexiconIndex) {\n      if (fuzzy.startsWith(word, partialWord, this.config.caseSensitive)) {\n        candidates.push(word);\n      }\n    }\n    \n    // In error-tolerant mode, also include fuzzy matches\n    if (this.config.errorTolerant && partialWord.length >= 2) {\n      const fuzzyMatches = fuzzy.fuzzyMatch(\n        partialWord,\n        Array.from(this.lexiconIndex),\n        this.config.maxEditDistance,\n        this.config.minSimilarity\n      );\n      \n      for (const match of fuzzyMatches) {\n        if (!candidates.includes(match.text)) {\n          candidates.push(match.text);\n        }\n      }\n    }\n    \n    // Score candidates using PPM model\n    return this._scoreCandidates(candidates, precedingContext);\n  }\n\n  /**\n   * Predict word completions using character-level model.\n   * @param {string} partialWord Partial word.\n   * @param {string} precedingContext Preceding context.\n   * @return {Array<Prediction>} Array of word predictions.\n   * @private\n   */\n  _predictCharacterBased(partialWord, precedingContext) {\n    const predictions = [];\n    const maxLength = 20; // Maximum word length to predict\n    \n    // Create a context with the preceding text and partial word\n    const fullContext = precedingContext + partialWord;\n    const workingContext = this.model.createContext();\n    \n    const chars = tokenizer.toCharArray(fullContext);\n    for (const char of chars) {\n      let symbolId = this.vocab.symbols_.indexOf(char);\n      if (symbolId >= 0) {\n        this.model.addSymbolToContext(workingContext, symbolId);\n      }\n    }\n    \n    // Generate completions by predicting next characters\n    const completions = this._generateCompletions(\n      workingContext,\n      partialWord,\n      maxLength - partialWord.length,\n      5 // Generate top 5 completions\n    );\n    \n    for (const completion of completions) {\n      predictions.push({\n        text: completion.text,\n        probability: completion.probability\n      });\n    }\n    \n    return predictions;\n  }\n\n  /**\n   * Generate word completions by predicting next characters.\n   * @param {Object} context PPM context.\n   * @param {string} prefix Current prefix.\n   * @param {number} maxChars Maximum characters to add.\n   * @param {number} numCompletions Number of completions to generate.\n   * @return {Array<Prediction>} Generated completions.\n   * @private\n   */\n  _generateCompletions(context, prefix, maxChars, numCompletions) {\n    const completions = [];\n    const spaceId = this.vocab.symbols_.indexOf(' ');\n    \n    // Simple beam search\n    let beams = [{ context: this.model.cloneContext(context), text: prefix, prob: 1.0 }];\n    \n    for (let i = 0; i < maxChars; i++) {\n      const newBeams = [];\n      \n      for (const beam of beams) {\n        const probs = this.model.getProbs(beam.context);\n        const topChars = [];\n        \n        // Get top characters\n        for (let j = 1; j < probs.length; j++) {\n          if (probs[j] > 0) {\n            topChars.push({ id: j, prob: probs[j] });\n          }\n        }\n        \n        topChars.sort((a, b) => b.prob - a.prob);\n        \n        // Expand beam with top characters\n        for (let k = 0; k < Math.min(3, topChars.length); k++) {\n          const charId = topChars[k].id;\n          const char = this.vocab.symbols_[charId];\n          \n          // Stop at space or newline\n          if (charId === spaceId || char === '\\n') {\n            if (beam.text.length > prefix.length) {\n              completions.push({ text: beam.text, probability: beam.prob });\n            }\n            continue;\n          }\n          \n          const newContext = this.model.cloneContext(beam.context);\n          this.model.addSymbolToContext(newContext, charId);\n          \n          newBeams.push({\n            context: newContext,\n            text: beam.text + char,\n            prob: beam.prob * topChars[k].prob\n          });\n        }\n      }\n      \n      if (newBeams.length === 0) break;\n      \n      // Keep top beams\n      newBeams.sort((a, b) => b.prob - a.prob);\n      beams = newBeams.slice(0, numCompletions);\n    }\n    \n    // Add remaining beams as completions\n    for (const beam of beams) {\n      if (beam.text.length > prefix.length) {\n        completions.push({ text: beam.text, probability: beam.prob });\n      }\n    }\n    \n    completions.sort((a, b) => b.probability - a.probability);\n    return completions.slice(0, numCompletions);\n  }\n\n  /**\n   * Score candidate words using the PPM model.\n   * @param {Array<string>} candidates Candidate words.\n   * @param {string} precedingContext Preceding context.\n   * @return {Array<Prediction>} Scored predictions.\n   * @private\n   */\n  _scoreCandidates(candidates, precedingContext) {\n    const predictions = [];\n    \n    for (const candidate of candidates) {\n      const score = this._scoreWord(candidate, precedingContext);\n      predictions.push({\n        text: candidate,\n        probability: score\n      });\n    }\n    \n    predictions.sort((a, b) => b.probability - a.probability);\n    return predictions.slice(0, this.config.maxPredictions);\n  }\n\n  /**\n   * Score a word using the PPM model.\n   * @param {string} word Word to score.\n   * @param {string} precedingContext Preceding context.\n   * @return {number} Score (probability).\n   * @private\n   */\n  _scoreWord(word, precedingContext) {\n    const fullText = precedingContext + word;\n    const workingContext = this.model.createContext();\n    \n    let logProb = 0;\n    const chars = tokenizer.toCharArray(fullText);\n    \n    for (const char of chars) {\n      const symbolId = this.vocab.symbols_.indexOf(char);\n      if (symbolId >= 0) {\n        const probs = this.model.getProbs(workingContext);\n        const prob = probs[symbolId] || 1e-10;\n        logProb += Math.log(prob);\n        this.model.addSymbolToContext(workingContext, symbolId);\n      }\n    }\n    \n    // Convert log probability to probability (normalized)\n    return Math.exp(logProb / chars.length);\n  }\n\n  /**\n   * Get configuration.\n   * @return {PredictorConfig} Current configuration.\n   */\n  getConfig() {\n    return { ...this.config };\n  }\n\n  /**\n   * Update configuration.\n   * @param {Partial<PredictorConfig>} newConfig Configuration updates.\n   */\n  updateConfig(newConfig) {\n    this.config = { ...this.config, ...newConfig };\n    \n    // Rebuild lexicon index if lexicon changed\n    if (newConfig.lexicon) {\n      this.lexiconIndex = new Set(this.config.lexicon.map(word => \n        this.config.caseSensitive ? word : word.toLowerCase()\n      ));\n    }\n  }\n}\n\n/**\n * Exported APIs.\n */\nexports.Predictor = Predictor;\n\n"],"names":["condition","message","Error","vocabulary","rootSymbol","Vocabulary","constructor","this","symbols_","Array","push","oovSymbol_","addSymbol","symbol","pos","indexOf","symbol_id","length","getSymbolOrOOV","size","assert","require$$0","vocab","require$$1","Node","child_","next_","backoff_","count_","symbol_","findChildWithSymbol","current","totalChildrenCounts","exclusionMask","childNode","count","Context","head","order","head_","order_","ppm_language_model","PPMLanguageModel","maxOrder","vocab_","maxOrder_","root_","rootContext_","numNodes_","useExclusion_","addSymbolToNode_","node","symbolNode","createContext","cloneContext","context","addSymbolToContext","addSymbolAndUpdate","getProbs","numSymbols","probs","i","totalMass","gamma","p","numUnseenSymbols","remainingMass","leftSymbols","newProbMass","Math","abs","printToConsole_","indent","console","log","child","printToConsole","levenshteinDistance","str1","str2","len1","len2","dp","fill","map","j","min","similarityScore","maxLen","max","getQwertyAdjacency","q","w","e","r","t","y","u","o","a","s","d","f","g","h","k","l","z","x","c","v","b","n","m","areKeysAdjacent","char1","char2","adjacency","c1","toLowerCase","c2","includes","fuzzyMatcher","startsWith","str","prefix","caseSensitive","fuzzyMatch","target","candidates","maxDistance","minSimilarity","matches","candidate","distance","similarity","text","sort","keyboardAwareDistance","substCost","toCharArray","from","wordTokenizer","tokenize","trim","split","filter","word","getLastPartialWord","trimmed","trimEnd","words","getContext","slice","join","endsWithWordBoundary","normalize","lowercase","normalized","fromCharArray","chars","isArray","getNgrams","ngrams","removePunctuation","replace","isAlphanumeric","char","test","isWhitespace","index_browserExports","predictorModule","ppm","fuzzy","require$$2","tokenizer","require$$3","predictor","Predictor","config","errorTolerant","undefined","maxEditDistance","keyboardAware","maxPredictions","adaptive","lexicon","String","fromCharCode","model","lexiconIndex","Set","train","symbolId","resetContext","addToContext","update","shouldUpdate","predictNextCharacter","workingContext","predictions","probability","predictWordCompletion","partialWord","precedingContext","_predictFromLexicon","_predictCharacterBased","fuzzyMatches","match","_scoreCandidates","fullContext","completions","_generateCompletions","completion","maxChars","numCompletions","spaceId","beams","prob","newBeams","beam","topChars","id","charId","newContext","score","_scoreWord","fullText","logProb","exp","getConfig","updateConfig","newConfig","ppmModule","vocabModule","require$$4","createPredictor","createStrictPredictor","createErrorTolerantPredictor","PPMPredictor","module","exports","window","index_browser","getDefaultExportFromCjs"],"mappings":"s6BACuB,SAAgBA,EAAWC,GACxC,IAAKD,EACH,MAAM,IAAIE,MAAMD,GAAW,mBAE/B,gDCqFRE,EAAAC,WArEmB,EAsEnBD,EAAAE,WAzDA,MACE,WAAAC,GACEC,KAAKC,SAAWC,QAChBF,KAAKC,SAASE,KAbK,OAcnBH,KAAKI,aACT,CAQE,SAAAC,CAAUC,GACR,IAAIC,EAAMP,KAAKC,SAASO,QAAQF,GAChC,GAAIC,GAAO,EACT,OAAOA,EAKT,MAAME,EAAYT,KAAKC,SAASS,OAEhC,OADAV,KAAKC,SAASE,KAAKG,GACZG,CACX,CAUE,cAAAE,CAAeL,GACb,IAAIC,EAAMP,KAAKC,SAASO,QAAQF,GAChC,OAAIC,GAAO,EACFA,GAETP,KAAKI,WAAaJ,KAAKK,UA9CT,SA+CPL,KAAKI,WAChB,CAOE,IAAAQ,GACE,OAAOZ,KAAKC,SAASS,MACzB,oCCxCA,MAAMG,EAASC,EAETC,EAAQC,IA4Bd,MAAMC,EACJ,WAAAlB,GAEEC,KAAKkB,OAAS,KAEdlB,KAAKmB,MAAQ,KAWbnB,KAAKoB,SAAW,KAGhBpB,KAAKqB,OAAS,EAEdrB,KAAKsB,QAAUP,EAAMlB,UACzB,CAQE,mBAAA0B,CAAoBjB,GAClB,IAAIkB,EAAUxB,KAAKkB,OACnB,KAAkB,MAAXM,GAAiB,CACtB,GAAIA,EAAQF,SAAWhB,EACrB,OAAOkB,EAETA,EAAUA,EAAQL,KACxB,CACI,OAAOK,CACX,CAmBE,mBAAAC,CAAoBC,GAClB,IAAIC,EAAY3B,KAAKkB,OACjBU,EAAQ,EACZ,KAAoB,MAAbD,GACAD,GAAkBA,EAAcC,EAAUL,WAC7CM,GAASD,EAAUN,QAErBM,EAAYA,EAAUR,MAExB,OAAOS,CACX,EAOA,MAAMC,EAMJ,WAAA9B,CAAY+B,EAAMC,GAEhB/B,KAAKgC,MAAQF,EAEb9B,KAAKiC,OAASF,CAClB,SA0UAG,EAAAC,iBAnUA,MAKE,WAAApC,CAAYgB,EAAOqB,GACjBpC,KAAKqC,OAAStB,EACdF,EAAOb,KAAKqC,OAAOzB,OAAS,EACrB,oDAEPZ,KAAKsC,UAAYF,EACjBpC,KAAKuC,MAAQ,IAAItB,EACjBjB,KAAKwC,aAAe,IAAIX,EACxB7B,KAAKwC,aAAaR,MAAQhC,KAAKuC,MAC/BvC,KAAKwC,aAAaP,OAAS,EAC3BjC,KAAKyC,UAAY,EAIjBzC,KAAK0C,eAAgB,CACzB,CASE,gBAAAC,CAAiBC,EAAMtC,GACrB,IAAIuC,EAAaD,EAAKrB,oBAAoBjB,GAsB1C,OArBkB,MAAduC,EAIFA,EAAWxB,UAIXwB,EAAa,IAAI5B,EACjB4B,EAAWvB,QAAUhB,EACrBuC,EAAW1B,MAAQyB,EAAK1B,OACxB0B,EAAK1B,OAAS2B,EACd7C,KAAKyC,YACDG,GAAQ5C,KAAKuC,MAEfM,EAAWzB,SAAWpB,KAAKuC,OAE3B1B,EAAwB,MAAjB+B,EAAKxB,SAAkB,+BAC9ByB,EAAWzB,SAAWpB,KAAK2C,iBAAiBC,EAAKxB,SAAUd,KAGxDuC,CACX,CAOE,aAAAC,GACE,OAAO,IAAIjB,EAAQ7B,KAAKwC,aAAaR,MAAOhC,KAAKwC,aAAaP,OAClE,CAQE,YAAAc,CAAaC,GACX,OAAO,IAAInB,EAAQmB,EAAQhB,MAAOgB,EAAQf,OAC9C,CAQE,kBAAAgB,CAAmBD,EAAS1C,GAC1B,KAAIA,GAAUS,EAAMlB,YAApB,CAIA,IADAgB,EAAOP,EAASN,KAAKqC,OAAOzB,OAAQ,mBAAqBN,GACjC,MAAjB0C,EAAQhB,OAAe,CAC5B,GAAIgB,EAAQf,OAASjC,KAAKsC,UAAW,CAEnC,MAAMX,EAAYqB,EAAQhB,MAAMT,oBAAoBjB,GACpD,GAAiB,MAAbqB,EAGF,OAFAqB,EAAQhB,MAAQL,OAChBqB,EAAQf,QAGlB,CAEMe,EAAQf,SACRe,EAAQhB,MAAQgB,EAAQhB,MAAMZ,QACpC,CACyB,MAAjB4B,EAAQhB,QACVgB,EAAQhB,MAAQhC,KAAKuC,MACrBS,EAAQf,OAAS,EAlBvB,CAoBA,CAQE,kBAAAiB,CAAmBF,EAAS1C,GAC1B,GAAIA,GAAUS,EAAMlB,WAClB,OAEFgB,EAAOP,EAASN,KAAKqC,OAAOzB,OAAQ,mBAAqBN,GACzD,MAAMuC,EAAa7C,KAAK2C,iBAAiBK,EAAQhB,MAAO1B,GAIxD,IAHAO,EAAOgC,GAAcG,EAAQhB,MAAMT,oBAAoBjB,IACvD0C,EAAQhB,MAAQa,EAChBG,EAAQf,SACDe,EAAQf,OAASjC,KAAKsC,WAC3BU,EAAQhB,MAAQgB,EAAQhB,MAAMZ,SAC9B4B,EAAQf,QAEd,CAgDE,QAAAkB,CAASH,GAGP,MAAMI,EAAapD,KAAKqC,OAAOzB,OAC/B,IAAIyC,EAAQ,IAAInD,MAAMkD,GACtB,IAAK,IAAIE,EAAI,EAAGA,EAAIF,IAAcE,EAChCD,EAAMC,GAAK,EAIb,IAAI5B,EAAgB,KACpB,GAAI1B,KAAK0C,cAAe,CACtBhB,EAAgB,IAAIxB,MAAMkD,GAC1B,IAAK,IAAIE,EAAI,EAAGA,EAAIF,IAAcE,EAChC5B,EAAc4B,IAAK,CAE3B,CAYI,IAAIC,EAAY,EACZX,EAAOI,EAAQhB,MACfwB,EAAQD,EACZ,KAAe,MAARX,GAAc,CACnB,MAAMhB,EAAQgB,EAAKnB,oBAAoBC,GACvC,GAAIE,EAAQ,EAAG,CACb,IAAID,EAAYiB,EAAK1B,OACrB,KAAoB,MAAbS,GAAmB,CACxB,MAAMrB,EAASqB,EAAUL,QACzB,IAAKI,IAAkBA,EAAcpB,GAAS,CAC5C,MAAMmD,EAAID,GAAS7B,EAAUN,OAlU1B,MAkU8CO,EAnU7C,KAoUJyB,EAAM/C,IAAWmD,EACjBF,GAAaE,EACT/B,IACFA,EAAcpB,IAAU,EAEtC,CACUqB,EAAYA,EAAUR,KAChC,CACA,CA8BMyB,EAAOA,EAAKxB,SACZoC,EAAQD,CACd,CACI1C,EAAO0C,GAAa,EACb,uCAAyCA,GAShD,IAAIG,EAAmB,EACvB,IAAK,IAAIJ,EAAI,EAAGA,EAAIF,IAAcE,EAC3B5B,GAAkBA,EAAc4B,IACnCI,IAKJ,MAAMC,EAAgBJ,EACtB,IAAK,IAAID,EAAI,EAAGA,EAAIF,IAAcE,EAGhC,IAAK5B,IAAkBA,EAAc4B,GAAI,CACvC,MAAMG,EAAIE,EAAgBD,EAC1BL,EAAMC,IAAMG,EACZF,GAAaE,CACrB,CAEI,IAAIG,EAAcR,EAAa,EAC3BS,EAAc,EAClB,IAAK,IAAIP,EAAI,EAAGA,EAAIF,IAAcE,EAAG,CACnC,MAAMG,EAAIF,EAAYK,EACtBP,EAAMC,IAAMG,EACZF,GAAaE,EACbI,GAAeR,EAAMC,KACnBM,CACR,CAGI,OAFA/C,EAAoB,GAAb0C,EAAkB,mDACzB1C,EAAOiD,KAAKC,IAAI,EAAMF,GA/YV,OAgZLR,CACX,CAQE,eAAAW,CAAgBpB,EAAMqB,GACpBC,QAAQC,IAAIF,EAAS,KAAOjE,KAAKqC,OAAOpC,SAAS2C,EAAKtB,SAC1C,IAAMsB,EAAKtB,QAAU,MAAQsB,EAAKvB,OAAS,KACvD4C,GAAU,KACV,IAAIG,EAAQxB,EAAK1B,OACjB,KAAgB,MAATkD,GACLpE,KAAKgE,gBAAgBI,EAAOH,GAC5BG,EAAQA,EAAMjD,KAEpB,CAME,cAAAkD,GACErE,KAAKgE,gBAAgBhE,KAAKuC,MAAO,GACrC,2CCzcA,SAAS+B,EAAoBC,EAAMC,GACjC,MAAMC,EAAOF,EAAK7D,OACZgE,EAAOF,EAAK9D,OAGZiE,EAAKzE,MAAMuE,EAAO,GAAGG,KAAK,MAAMC,IAAI,IAAM3E,MAAMwE,EAAO,GAAGE,KAAK,IAGrE,IAAK,IAAItB,EAAI,EAAGA,GAAKmB,EAAMnB,IACzBqB,EAAGrB,GAAG,GAAKA,EAEb,IAAK,IAAIwB,EAAI,EAAGA,GAAKJ,EAAMI,IACzBH,EAAG,GAAGG,GAAKA,EAIb,IAAK,IAAIxB,EAAI,EAAGA,GAAKmB,EAAMnB,IACzB,IAAK,IAAIwB,EAAI,EAAGA,GAAKJ,EAAMI,IACrBP,EAAKjB,EAAI,KAAOkB,EAAKM,EAAI,GAC3BH,EAAGrB,GAAGwB,GAAKH,EAAGrB,EAAI,GAAGwB,EAAI,GAEzBH,EAAGrB,GAAGwB,GAAKhB,KAAKiB,IACdJ,EAAGrB,EAAI,GAAGwB,GAAK,EACfH,EAAGrB,GAAGwB,EAAI,GAAK,EACfH,EAAGrB,EAAI,GAAGwB,EAAI,GAAK,GAM3B,OAAOH,EAAGF,GAAMC,EAClB,CAQA,SAASM,EAAgBT,EAAMC,GAC7B,MAAMS,EAASnB,KAAKoB,IAAIX,EAAK7D,OAAQ8D,EAAK9D,QAC1C,GAAe,IAAXuE,EAAc,OAAO,EAGzB,OAAO,EADUX,EAAoBC,EAAMC,GAClBS,CAC3B,CA0DA,SAASE,IACP,MAAO,CACLC,EAAK,CAAC,IAAK,IAAK,KAChBC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BpC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BqC,EAAK,CAAC,IAAK,IAAK,IAAK,KACrBlC,EAAK,CAAC,IAAK,KACXmC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACzCC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACzCC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACzCC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACzCC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACzCnB,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACpCoB,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,KAC/BC,EAAK,CAAC,IAAK,IAAK,IAAK,KACrBC,EAAK,CAAC,IAAK,IAAK,KAChBC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,KAEzB,CAQA,SAASC,EAAgBC,EAAOC,GAC9B,MAAMC,EArCC,CACL1B,EAAK,CAAC,IAAK,IAAK,KAChBC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BpC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BqC,EAAK,CAAC,IAAK,IAAK,IAAK,KACrBlC,EAAK,CAAC,IAAK,KACXmC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACzCC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACzCC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACzCC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACzCC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACzCnB,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,IAAK,KACpCoB,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,KAC/BC,EAAK,CAAC,IAAK,IAAK,IAAK,KACrBC,EAAK,CAAC,IAAK,IAAK,KAChBC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,IAAK,KAC1BC,EAAK,CAAC,IAAK,IAAK,IAAK,MAYjBK,EAAKH,EAAMI,cACXC,EAAKJ,EAAMG,cAEjB,OAAOF,EAAUC,IAAOD,EAAUC,GAAIG,SAASD,EACjD,YA6CAE,EAAA7C,oBAA8BA,EAC9B6C,EAAAnC,gBAA0BA,EAC1BmC,EAAAC,WA3IA,SAAoBC,EAAKC,EAAQC,GAAgB,GAK/C,OAJKA,IACHF,EAAMA,EAAIL,cACVM,EAASA,EAAON,eAEXK,EAAID,WAAWE,EACxB,EAsIAH,EAAAK,WA3HA,SAAoBC,EAAQC,EAAYC,EAAc,EAAGC,EAAgB,IACvE,MAAMC,EAAU,GAEhB,IAAK,MAAMC,KAAaJ,EAAY,CAClC,MAAMK,EAAWzD,EAAoBmD,EAAQK,GACvCE,EAAahD,EAAgByC,EAAQK,GAEvCC,GAAYJ,GAAeK,GAAcJ,GAC3CC,EAAQ1H,KAAK,CACX8H,KAAMH,EACNC,SAAUA,EACVC,WAAYA,GAGpB,CAUE,OAPAH,EAAQK,KAAK,CAACtC,EAAGY,IACX1C,KAAKC,IAAI6B,EAAEoC,WAAaxB,EAAEwB,YAAc,KACnCxB,EAAEwB,WAAapC,EAAEoC,WAEnBpC,EAAEmC,SAAWvB,EAAEuB,UAGjBF,CACT,EAmGAV,EAAAhC,mBAA6BA,EAC7BgC,EAAAR,gBAA0BA,EAC1BQ,EAAAgB,sBA1CA,SAA+B5D,EAAMC,GACnC,MAAMC,EAAOF,EAAK7D,OACZgE,EAAOF,EAAK9D,OAEZiE,EAAKzE,MAAMuE,EAAO,GAAGG,KAAK,MAAMC,IAAI,IAAM3E,MAAMwE,EAAO,GAAGE,KAAK,IAErE,IAAK,IAAItB,EAAI,EAAGA,GAAKmB,EAAMnB,IACzBqB,EAAGrB,GAAG,GAAKA,EAEb,IAAK,IAAIwB,EAAI,EAAGA,GAAKJ,EAAMI,IACzBH,EAAG,GAAGG,GAAKA,EAGb,IAAK,IAAIxB,EAAI,EAAGA,GAAKmB,EAAMnB,IACzB,IAAK,IAAIwB,EAAI,EAAGA,GAAKJ,EAAMI,IACzB,GAAIP,EAAKjB,EAAI,KAAOkB,EAAKM,EAAI,GAC3BH,EAAGrB,GAAGwB,GAAKH,EAAGrB,EAAI,GAAGwB,EAAI,OACpB,CAEL,MAAMsD,EAAYzB,EAAgBpC,EAAKjB,EAAI,GAAIkB,EAAKM,EAAI,IAAM,GAAM,EAEpEH,EAAGrB,GAAGwB,GAAKhB,KAAKiB,IACdJ,EAAGrB,EAAI,GAAGwB,GAAK,EACfH,EAAGrB,GAAGwB,EAAI,GAAK,EACfH,EAAGrB,EAAI,GAAGwB,EAAI,GAAKsD,EAE7B,CAIE,OAAOzD,EAAGF,GAAMC,EAClB,8CC9FA,SAAS2D,EAAYJ,GACnB,OAAKA,GAAwB,iBAATA,EAIb/H,MAAMoI,KAAKL,GAHT,EAIX,YA8EAM,EAAAC,SAjLA,SAAkBP,GAChB,OAAKA,GAAwB,iBAATA,EAKbA,EAAKQ,OAAOC,MAAM,OAAOC,OAAOC,GAAQA,EAAKlI,OAAS,GAJpD,EAKX,EA2KA6H,EAAAM,mBApKA,SAA4BZ,GAC1B,IAAKA,GAAwB,iBAATA,EAClB,MAAO,GAGT,MAAMa,EAAUb,EAAKc,UACfC,EAAQF,EAAQJ,MAAM,OAG5B,OAAIT,IAASa,EACJ,GAGFE,EAAMA,EAAMtI,OAAS,IAAM,EACpC,EAuJA6H,EAAAU,WAhJA,SAAoBhB,GAClB,IAAKA,GAAwB,iBAATA,EAClB,MAAO,GAGT,MAAMa,EAAUb,EAAKc,UACfC,EAAQF,EAAQJ,MAAM,OAG5B,OAAIT,IAASa,EACJA,EAILE,EAAMtI,QAAU,EACX,GAGFsI,EAAME,MAAM,GAAG,GAAIC,KAAK,IACjC,EA8HAZ,EAAAa,qBAvHA,SAA8BnB,GAC5B,OAAKA,GAAwB,iBAATA,GAIbA,IAASA,EAAKc,SACvB,EAkHAR,EAAAc,UA1GA,SAAmBpB,EAAMqB,GAAY,GACnC,IAAKrB,GAAwB,iBAATA,EAClB,MAAO,GAGT,IAAIsB,EAAatB,EAAKQ,OAKtB,OAJIa,IACFC,EAAaA,EAAWvC,eAGnBuC,CACT,EAgGAhB,EAAAF,YAAsBA,EACtBE,EAAAiB,cA7EA,SAAuBC,GACrB,OAAKvJ,MAAMwJ,QAAQD,GAIZA,EAAMN,KAAK,IAHT,EAIX,EAwEAZ,EAAAoB,UAhEA,SAAmB1B,EAAMxB,GACvB,IAAKwB,GAAwB,iBAATA,GAAqBxB,EAAI,EAC3C,MAAO,GAGT,MAAMgD,EAAQpB,EAAYJ,GACpB2B,EAAS,GAEf,IAAK,IAAItG,EAAI,EAAGA,GAAKmG,EAAM/I,OAAS+F,EAAGnD,IACrCsG,EAAOzJ,KAAKsJ,EAAMP,MAAM5F,EAAGA,EAAImD,GAAG0C,KAAK,KAGzC,OAAOS,CACT,EAoDArB,EAAAsB,kBA7CA,SAA2B5B,GACzB,OAAKA,GAAwB,iBAATA,EAIbA,EAAK6B,QAAQ,WAAY,IAHvB,EAIX,EAwCAvB,EAAAwB,eAjCA,SAAwBC,GACtB,SAAKA,GAAwB,iBAATA,GAAqC,IAAhBA,EAAKtJ,SAIvC,gBAAgBuJ,KAAKD,EAC9B,EA4BAzB,EAAA2B,aArBA,SAAsBF,GACpB,SAAKA,GAAwB,iBAATA,GAAqC,IAAhBA,EAAKtJ,SAIvC,OAAOuJ,KAAKD,EACrB,ICpMA,IAAIG,uBCmBJ,MAAMC,+BCDN,MAAMC,EAAMvJ,IACNC,EAAQC,IACRsJ,EAAQC,IACRC,EAAYC,WA+ZlBC,EAAAC,UAnYA,MAKE,WAAA5K,CAAY6K,EAAS,IAEnB5K,KAAK4K,OAAS,CACZxI,SAAUwI,EAAOxI,UAAY,EAC7ByI,mBAAwCC,IAAzBF,EAAOC,eAA8BD,EAAOC,cAC3DE,gBAAiBH,EAAOG,iBAAmB,EAC3CnD,cAAegD,EAAOhD,eAAiB,GACvCoD,mBAAwCF,IAAzBF,EAAOI,eAA8BJ,EAAOI,cAC3DzD,mBAAwCuD,IAAzBF,EAAOrD,eAA8BqD,EAAOrD,cAC3D0D,eAAgBL,EAAOK,gBAAkB,GACzCC,cAA8BJ,IAApBF,EAAOM,UAAyBN,EAAOM,SACjDC,QAASP,EAAOO,SAAW,IAI7BnL,KAAKe,MAAQ,IAAIA,EAAMjB,WAGvB,IAAK,IAAIwD,EAAI,GAAIA,GAAK,IAAKA,IACzBtD,KAAKe,MAAMV,UAAU+K,OAAOC,aAAa/H,IAI3CtD,KAAKe,MAAMV,UAAU,MACrBL,KAAKe,MAAMV,UAAU,MAGrBL,KAAKsL,MAAQ,IAAIjB,EAAIlI,iBAAiBnC,KAAKe,MAAOf,KAAK4K,OAAOxI,UAG9DpC,KAAKgD,QAAUhD,KAAKsL,MAAMxI,gBAG1B9C,KAAKuL,aAAe,IAAIC,IAAIxL,KAAK4K,OAAOO,QAAQtG,IAAI+D,GAClD5I,KAAK4K,OAAOrD,cAAgBqB,EAAOA,EAAK5B,eAE9C,CAME,KAAAyE,CAAMxD,GACJ,IAAKA,GAAwB,iBAATA,EAClB,OAGF,MAAMwB,EAAQe,EAAUnC,YAAYJ,GAC9BjF,EAAUhD,KAAKsL,MAAMxI,gBAE3B,IAAK,MAAMkH,KAAQP,EAAO,CACxB,MAAMiC,EAAW1L,KAAKe,MAAMV,UAAU2J,GACtChK,KAAKsL,MAAMpI,mBAAmBF,EAAS0I,EAC7C,CACA,CAKE,YAAAC,GACE3L,KAAKgD,QAAUhD,KAAKsL,MAAMxI,eAC9B,CAOE,YAAA8I,CAAa3D,EAAM4D,EAAS,MAC1B,IAAK5D,GAAwB,iBAATA,EAClB,OAGF,MAAM6D,EAA0B,OAAXD,EAAkBA,EAAS7L,KAAK4K,OAAOM,SACtDzB,EAAQe,EAAUnC,YAAYJ,GAEpC,IAAK,MAAM+B,KAAQP,EAAO,CACxB,IAAIiC,EAAW1L,KAAKe,MAAMd,SAASO,QAAQwJ,GACvC0B,EAAW,IACbA,EAAW1L,KAAKe,MAAMV,UAAU2J,IAG9B8B,EACF9L,KAAKsL,MAAMpI,mBAAmBlD,KAAKgD,QAAS0I,GAE5C1L,KAAKsL,MAAMrI,mBAAmBjD,KAAKgD,QAAS0I,EAEpD,CACA,CAOE,oBAAAK,CAAqB/I,EAAU,MAC7B,IAAIgJ,EAAiBhM,KAAKgD,QAE1B,GAAgB,OAAZA,EAAkB,CACpBgJ,EAAiBhM,KAAKsL,MAAMxI,gBAC5B,MAAM2G,EAAQe,EAAUnC,YAAYrF,GACpC,IAAK,MAAMgH,KAAQP,EAAO,CACxB,IAAIiC,EAAW1L,KAAKe,MAAMd,SAASO,QAAQwJ,GACvC0B,EAAW,IACbA,EAAW1L,KAAKe,MAAMV,UAAU2J,IAElChK,KAAKsL,MAAMrI,mBAAmB+I,EAAgBN,EACtD,CACA,CAGI,MAAMrI,EAAQrD,KAAKsL,MAAMnI,SAAS6I,GAG5BC,EAAc,GACpB,IAAK,IAAI3I,EAAI,EAAGA,EAAID,EAAM3C,OAAQ4C,IAC5BD,EAAMC,GAAK,GACb2I,EAAY9L,KAAK,CACf8H,KAAMjI,KAAKe,MAAMd,SAASqD,GAC1B4I,YAAa7I,EAAMC,KASzB,OAHA2I,EAAY/D,KAAK,CAACtC,EAAGY,IAAMA,EAAE0F,YAActG,EAAEsG,aAGtCD,EAAY/C,MAAM,EAAGlJ,KAAK4K,OAAOK,eAC5C,CAQE,qBAAAkB,CAAsBC,EAAaC,EAAmB,IACpD,IAAKD,GAAsC,iBAAhBA,EACzB,MAAO,GAGT,MAAM7C,EAAavJ,KAAK4K,OAAOrD,cAAgB6E,EAAcA,EAAYpF,cAGzE,OAAIhH,KAAKuL,aAAa3K,KAAO,EACpBZ,KAAKsM,oBAAoB/C,EAAY8C,GAIvCrM,KAAKuM,uBAAuBH,EAAaC,EACpD,CASE,mBAAAC,CAAoBF,EAAaC,GAC/B,MAAM3E,EAAa,GAGnB,IAAK,MAAMkB,KAAQ5I,KAAKuL,aAClBjB,EAAMlD,WAAWwB,EAAMwD,EAAapM,KAAK4K,OAAOrD,gBAClDG,EAAWvH,KAAKyI,GAKpB,GAAI5I,KAAK4K,OAAOC,eAAiBuB,EAAY1L,QAAU,EAAG,CACxD,MAAM8L,EAAelC,EAAM9C,WACzB4E,EACAlM,MAAMoI,KAAKtI,KAAKuL,cAChBvL,KAAK4K,OAAOG,gBACZ/K,KAAK4K,OAAOhD,eAGd,IAAK,MAAM6E,KAASD,EACb9E,EAAWR,SAASuF,EAAMxE,OAC7BP,EAAWvH,KAAKsM,EAAMxE,KAGhC,CAGI,OAAOjI,KAAK0M,iBAAiBhF,EAAY2E,EAC7C,CASE,sBAAAE,CAAuBH,EAAaC,GAClC,MAAMJ,EAAc,GAIdU,EAAcN,EAAmBD,EACjCJ,EAAiBhM,KAAKsL,MAAMxI,gBAE5B2G,EAAQe,EAAUnC,YAAYsE,GACpC,IAAK,MAAM3C,KAAQP,EAAO,CACxB,IAAIiC,EAAW1L,KAAKe,MAAMd,SAASO,QAAQwJ,GACvC0B,GAAY,GACd1L,KAAKsL,MAAMrI,mBAAmB+I,EAAgBN,EAEtD,CAGI,MAAMkB,EAAc5M,KAAK6M,qBACvBb,EACAI,EAjBgB,GAkBJA,EAAY1L,OACxB,GAGF,IAAK,MAAMoM,KAAcF,EACvBX,EAAY9L,KAAK,CACf8H,KAAM6E,EAAW7E,KACjBiE,YAAaY,EAAWZ,cAI5B,OAAOD,CACX,CAWE,oBAAAY,CAAqB7J,EAASsE,EAAQyF,EAAUC,GAC9C,MAAMJ,EAAc,GACdK,EAAUjN,KAAKe,MAAMd,SAASO,QAAQ,KAG5C,IAAI0M,EAAQ,CAAC,CAAElK,QAAShD,KAAKsL,MAAMvI,aAAaC,GAAUiF,KAAMX,EAAQ6F,KAAM,IAE9E,IAAK,IAAI7J,EAAI,EAAGA,EAAIyJ,EAAUzJ,IAAK,CACjC,MAAM8J,EAAW,GAEjB,IAAK,MAAMC,KAAQH,EAAO,CACxB,MAAM7J,EAAQrD,KAAKsL,MAAMnI,SAASkK,EAAKrK,SACjCsK,EAAW,GAGjB,IAAK,IAAIxI,EAAI,EAAGA,EAAIzB,EAAM3C,OAAQoE,IAC5BzB,EAAMyB,GAAK,GACbwI,EAASnN,KAAK,CAAEoN,GAAIzI,EAAGqI,KAAM9J,EAAMyB,KAIvCwI,EAASpF,KAAK,CAACtC,EAAGY,IAAMA,EAAE2G,KAAOvH,EAAEuH,MAGnC,IAAK,IAAIjH,EAAI,EAAGA,EAAIpC,KAAKiB,IAAI,EAAGuI,EAAS5M,QAASwF,IAAK,CACrD,MAAMsH,EAASF,EAASpH,GAAGqH,GACrBvD,EAAOhK,KAAKe,MAAMd,SAASuN,GAGjC,GAAIA,IAAWP,GAAoB,OAATjD,EAAe,CACnCqD,EAAKpF,KAAKvH,OAAS4G,EAAO5G,QAC5BkM,EAAYzM,KAAK,CAAE8H,KAAMoF,EAAKpF,KAAMiE,YAAamB,EAAKF,OAExD,QACZ,CAEU,MAAMM,EAAazN,KAAKsL,MAAMvI,aAAasK,EAAKrK,SAChDhD,KAAKsL,MAAMrI,mBAAmBwK,EAAYD,GAE1CJ,EAASjN,KAAK,CACZ6C,QAASyK,EACTxF,KAAMoF,EAAKpF,KAAO+B,EAClBmD,KAAME,EAAKF,KAAOG,EAASpH,GAAGiH,MAE1C,CACA,CAEM,GAAwB,IAApBC,EAAS1M,OAAc,MAG3B0M,EAASlF,KAAK,CAACtC,EAAGY,IAAMA,EAAE2G,KAAOvH,EAAEuH,MACnCD,EAAQE,EAASlE,MAAM,EAAG8D,EAChC,CAGI,IAAK,MAAMK,KAAQH,EACbG,EAAKpF,KAAKvH,OAAS4G,EAAO5G,QAC5BkM,EAAYzM,KAAK,CAAE8H,KAAMoF,EAAKpF,KAAMiE,YAAamB,EAAKF,OAK1D,OADAP,EAAY1E,KAAK,CAACtC,EAAGY,IAAMA,EAAE0F,YAActG,EAAEsG,aACtCU,EAAY1D,MAAM,EAAG8D,EAChC,CASE,gBAAAN,CAAiBhF,EAAY2E,GAC3B,MAAMJ,EAAc,GAEpB,IAAK,MAAMnE,KAAaJ,EAAY,CAClC,MAAMgG,EAAQ1N,KAAK2N,WAAW7F,EAAWuE,GACzCJ,EAAY9L,KAAK,CACf8H,KAAMH,EACNoE,YAAawB,GAErB,CAGI,OADAzB,EAAY/D,KAAK,CAACtC,EAAGY,IAAMA,EAAE0F,YAActG,EAAEsG,aACtCD,EAAY/C,MAAM,EAAGlJ,KAAK4K,OAAOK,eAC5C,CASE,UAAA0C,CAAW/E,EAAMyD,GACf,MAAMuB,EAAWvB,EAAmBzD,EAC9BoD,EAAiBhM,KAAKsL,MAAMxI,gBAElC,IAAI+K,EAAU,EACd,MAAMpE,EAAQe,EAAUnC,YAAYuF,GAEpC,IAAK,MAAM5D,KAAQP,EAAO,CACxB,MAAMiC,EAAW1L,KAAKe,MAAMd,SAASO,QAAQwJ,GAC7C,GAAI0B,GAAY,EAAG,CACjB,MACMyB,EADQnN,KAAKsL,MAAMnI,SAAS6I,GACfN,IAAa,MAChCmC,GAAW/J,KAAKK,IAAIgJ,GACpBnN,KAAKsL,MAAMrI,mBAAmB+I,EAAgBN,EACtD,CACA,CAGI,OAAO5H,KAAKgK,IAAID,EAAUpE,EAAM/I,OACpC,CAME,SAAAqN,GACE,MAAO,IAAK/N,KAAK4K,OACrB,CAME,YAAAoD,CAAaC,GACXjO,KAAK4K,OAAS,IAAK5K,KAAK4K,UAAWqD,GAG/BA,EAAU9C,UACZnL,KAAKuL,aAAe,IAAIC,IAAIxL,KAAK4K,OAAOO,QAAQtG,IAAI+D,GAClD5I,KAAK4K,OAAOrD,cAAgBqB,EAAOA,EAAK5B,gBAGhD,KD3ZwBlG,GAClBoN,EAAYlN,IACZmN,EAAc5D,IACdpD,EAAesD,IACflC,EAAgB6F,IAGhBzD,EAAYP,EAAgBO,WAAaP,EACzCjI,EAAmB+L,EAAU/L,kBAAoB+L,EACjDpO,EAAaqO,EAAYrO,YAAcqO,EAQ7C,SAASE,EAAgBzD,EAAS,IAChC,OAAO,IAAID,EAAUC,EACvB,CAQA,SAAS0D,EAAsB1D,EAAS,IACtC,OAAO,IAAID,EAAU,IAChBC,EACHC,eAAe,GAEnB,CAQA,SAAS0D,EAA6B3D,EAAS,IAC7C,OAAO,IAAID,EAAU,IAChBC,EACHC,eAAe,GAEnB,CAGA,MAAM2D,EAAe,CAEnBH,kBACAC,wBACAC,+BAGA5D,YACAxI,mBACArC,aAGAqH,eACAoB,gBAGAjE,oBAAqB6C,EAAa7C,oBAClCU,gBAAiBmC,EAAanC,gBAC9BwC,WAAYL,EAAaK,YAIUiH,EAAOC,UAE1CD,UAAiBD,EACjBC,0BAAiCJ,EACjCI,gCAAuCH,EACvCG,uCAA8CF,EAC9CE,oBAA2B9D,EAC3B8D,2BAAkCtM,EAClCsM,qBAA4B3O,EAC5B2O,uBAA8BtH,EAC9BsH,wBAA+BlG,EAC/BkG,EAAAC,QAAApK,oBAAqC6C,EAAa7C,oBAClDmK,EAAAC,QAAA1J,gBAAiCmC,EAAanC,gBAC9CyJ,EAAAC,QAAAlH,WAA4BL,EAAaK,YAGrB,oBAAXmH,SAETA,OAAOH,aAAeA,GAIxBC,EAAAC,QAAiBF,kBD7GjBI,EAA4BC,EAAwB1E"}